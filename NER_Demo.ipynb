{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_Demo.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qQwulC5oaW8-",
        "EnN_WBNLY7AE",
        "3KbSuxLBY_vQ",
        "8aCoayOCZZOe",
        "I7mbayPNfO4o",
        "LO4l7xh5gLhj"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marcelo-morales/russell-csie/blob/main/NER_Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Spacy NER Demo\n",
        "Caveats: Entity labels are not custom. We repurposing some of the predefined ones.\n",
        "\n",
        "Thus for our purposes:\n",
        "\n",
        "| Predefined Label  | Corresponds to our label \n",
        "| --- | --- |\n",
        "ORG | glasses\n",
        "DATE | hair_color\n",
        "NORP | hat_color\n",
        "GPE | hat\n",
        "LAW | bald\n",
        "\n",
        "Repurposing tutorial from: https://www.machinelearningplus.com/nlp/training-custom-ner-model-in-spacy/\n",
        "\n"
      ],
      "metadata": {
        "id": "ktEzEcXEYJrS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load pre-existing spacy model\n",
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm')\n",
        "\n",
        "# Getting the pipeline component\n",
        "ner=nlp.get_pipe(\"ner\")"
      ],
      "metadata": {
        "id": "5AkTUzVleUot"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Example from tutorial"
      ],
      "metadata": {
        "id": "I7mbayPNfO4o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training data\n",
        "TRAIN_DATA = [\n",
        "              (\"Walmart is a leading e-commerce company\", {\"entities\": [(0, 7, \"ORG\")]}),\n",
        "              (\"I reached Chennai yesterday.\", {\"entities\": [(19, 28, \"GPE\")]}),\n",
        "              (\"I recently ordered a book from Amazon\", {\"entities\": [(24,32, \"ORG\")]}),\n",
        "              (\"I was driving a BMW\", {\"entities\": [(16,19, \"PRODUCT\")]}),\n",
        "              (\"I ordered this from ShopClues\", {\"entities\": [(20,29, \"ORG\")]}),\n",
        "              (\"Fridge can be ordered in Amazon \", {\"entities\": [(0,6, \"PRODUCT\")]}),\n",
        "              (\"I bought a new Washer\", {\"entities\": [(16,22, \"PRODUCT\")]}),\n",
        "              (\"I bought a old table\", {\"entities\": [(16,21, \"PRODUCT\")]}),\n",
        "              (\"I bought a fancy dress\", {\"entities\": [(18,23, \"PRODUCT\")]}),\n",
        "              (\"I rented a camera\", {\"entities\": [(12,18, \"PRODUCT\")]}),\n",
        "              (\"I rented a tent for our trip\", {\"entities\": [(12,16, \"PRODUCT\")]}),\n",
        "              (\"I rented a screwdriver from our neighbour\", {\"entities\": [(12,22, \"PRODUCT\")]}),\n",
        "              (\"I repaired my computer\", {\"entities\": [(15,23, \"PRODUCT\")]}),\n",
        "              (\"I got my clock fixed\", {\"entities\": [(16,21, \"PRODUCT\")]}),\n",
        "              (\"I got my truck fixed\", {\"entities\": [(16,21, \"PRODUCT\")]}),\n",
        "              (\"Flipkart started it's journey from zero\", {\"entities\": [(0,8, \"ORG\")]}),\n",
        "              (\"I recently ordered from Max\", {\"entities\": [(24,27, \"ORG\")]}),\n",
        "              (\"Flipkart is recognized as leader in market\",{\"entities\": [(0,8, \"ORG\")]}),\n",
        "              (\"I recently ordered from Swiggy\", {\"entities\": [(24,29, \"ORG\")]})\n",
        "              ]\n",
        "\n",
        "# Adding labels to the `ner`\n",
        "\n",
        "for _, annotations in TRAIN_DATA:\n",
        "  for ent in annotations.get(\"entities\"):\n",
        "    ner.add_label(ent[2])\n",
        "\n",
        "# Disable pipeline components you dont need to change\n",
        "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
      ],
      "metadata": {
        "id": "lNKbYXraelvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Our Training Data - Defining the entity locations using char offsets"
      ],
      "metadata": {
        "id": "Xq-cIMFufRer"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# training data\n",
        "## ORG - glasses\n",
        "## DATE - hair_color\n",
        "## NORP - hat_color\n",
        "## GPE = hat\n",
        "## LAW - bald\n",
        "TRAIN_DATA = [\n",
        "              (\"Is your person wearing glasses?\", {\"entities\": [(23,30,\"ORG\")]}),\n",
        "              (\"Do they have glasses?\", {\"entities\": [(13,20,\"ORG\")]}),\n",
        "              (\"Does your person have glasses on?\", {\"entities\": [(22,29,\"ORG\")]}),\n",
        "\n",
        "              (\"Is your person four-eyed?\", {\"entities\": [(15,24,\"ORG\")]}),\n",
        "              (\"Is she four-eyed?\", {\"entities\": [(7,16,\"ORG\")]}),\n",
        "\n",
        "              (\"Is she blond?\", {\"entities\": [(7,12,\"DATE\")]}),\n",
        "              (\"Is your person blond-haired?\", {\"entities\": [(15,20,\"DATE\")]}),\n",
        "              (\"Is he golden-haired?\", {\"entities\": [(6,12,\"DATE\")]}),\n",
        "              (\"Are they gold-haired?\", {\"entities\": [(9,13,\"DATE\")]}),\n",
        "              (\"Does your person have yellow hair?\", {\"entities\": [(22,28,\"DATE\")]}),\n",
        "              (\"Are they auburn-haired?\", {\"entities\": [(9,15,\"DATE\")]}),\n",
        "              (\"Is your person a ginger?\", {\"entities\": [(17,24,\"DATE\")]}),              \n",
        "              \n",
        "              (\"Is your person wearing a green hat?\", {\"entities\": [(25,30,\"NORP\")]}),\n",
        "              (\"Are they wearing a green hat?\", {\"entities\": [(19,24,\"NORP\")]}),\n",
        "              (\"Does your person have a green hat?\", {\"entities\": [(24,29,\"NORP\")]}), \n",
        "              (\"Do they have a green hat?\", {\"entities\": [(15,20,\"NORP\")]}),\n",
        "\n",
        "              (\"Does your person wear a hat?\", {\"entities\": [(24,27,\"GPE\")]}), \n",
        "              (\"Do they wear a hat?\", {\"entities\": [(15,18,\"GPE\")]}), \n",
        "              (\"Do they have a hat?\", {\"entities\": [(15,18,\"GPE\")]}), \n",
        "\n",
        "              (\"Does your person not have head hair?\", {\"entities\": [(17,35,\"LAW\")]}),\n",
        "              (\"Is your person bald?\", {\"entities\": [(15,19,\"LAW\")]}),\n",
        "              (\"Is she bald?\", {\"entities\": [(7,13,\"LAW\")]}),\n",
        "              (\"Is he bald?\", {\"entities\": [(6,10,\"LAW\")]}),\n",
        "              (\"Does he not have head hair?\", {\"entities\": [(8,26,\"LAW\")]}),\n",
        "              (\"Does he not have hair on his head?\", {\"entities\": [(8,33,\"LAW\")]})                                          \n",
        "              # (\"Walmart is a leading e-commerce company\", {\"entities\": [(0, 7, \"ORG\")]})\n",
        "              ]\n",
        "\n",
        "# Adding labels to the `ner`\n",
        "\n",
        "for _, annotations in TRAIN_DATA:\n",
        "  for ent in annotations.get(\"entities\"):\n",
        "    ner.add_label(ent[2])\n",
        "\n",
        "# Disable pipeline components you dont need to change\n",
        "pipe_exceptions = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "unaffected_pipes = [pipe for pipe in nlp.pipe_names if pipe not in pipe_exceptions]"
      ],
      "metadata": {
        "id": "Uyw7NldXfNBh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the model - Losses printed"
      ],
      "metadata": {
        "id": "tL_mf98b6v0Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import requirements\n",
        "import random\n",
        "from spacy.util import minibatch, compounding\n",
        "from pathlib import Path\n",
        "\n",
        "# TRAINING THE MODEL\n",
        "with nlp.disable_pipes(*unaffected_pipes):\n",
        "\n",
        "  # Training for 30 iterations\n",
        "  for iteration in range(30):\n",
        "\n",
        "    # shuufling examples  before every iteration\n",
        "    random.shuffle(TRAIN_DATA)\n",
        "    losses = {}\n",
        "    # batch up the examples using spaCy's minibatch\n",
        "    batches = minibatch(TRAIN_DATA, size=compounding(4.0, 32.0, 1.001))\n",
        "    for batch in batches:\n",
        "        texts, annotations = zip(*batch)\n",
        "        nlp.update(\n",
        "                    texts,  # batch of texts\n",
        "                    annotations,  # batch of annotations\n",
        "                    drop=0.5,  # dropout - make it harder to memorise data\n",
        "                    losses=losses,\n",
        "                )\n",
        "    print(\"Losses\", losses)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DXiwptMSev1x",
        "outputId": "79f5b939-0169-4a0d-f50a-f6605b93109f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Losses {'ner': 60.78092178907338}\n",
            "Losses {'ner': 57.168306567298714}\n",
            "Losses {'ner': 68.30356031383872}\n",
            "Losses {'ner': 66.26109631008876}\n",
            "Losses {'ner': 57.86614957496079}\n",
            "Losses {'ner': 53.14728559450036}\n",
            "Losses {'ner': 66.9493131988711}\n",
            "Losses {'ner': 46.983277083960076}\n",
            "Losses {'ner': 48.22391544936295}\n",
            "Losses {'ner': 43.01519218170206}\n",
            "Losses {'ner': 50.54340357534022}\n",
            "Losses {'ner': 38.87983047587146}\n",
            "Losses {'ner': 32.00890809057637}\n",
            "Losses {'ner': 32.32324995709171}\n",
            "Losses {'ner': 22.396071723321256}\n",
            "Losses {'ner': 30.630119889849766}\n",
            "Losses {'ner': 31.20321326529482}\n",
            "Losses {'ner': 26.473462673157854}\n",
            "Losses {'ner': 36.792397848896954}\n",
            "Losses {'ner': 26.155820381203057}\n",
            "Losses {'ner': 26.946532395624963}\n",
            "Losses {'ner': 31.71347818613943}\n",
            "Losses {'ner': 19.43176520472117}\n",
            "Losses {'ner': 17.79637048298499}\n",
            "Losses {'ner': 21.226841466851738}\n",
            "Losses {'ner': 24.72095092418546}\n",
            "Losses {'ner': 14.20075231124407}\n",
            "Losses {'ner': 21.44121767107182}\n",
            "Losses {'ner': 19.694773515577243}\n",
            "Losses {'ner': 16.293431613580594}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tutorial Example"
      ],
      "metadata": {
        "id": "LO4l7xh5gLhj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "doc = nlp(\"I was driving a Alto\")\n",
        "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
        "\n",
        "from spacy import displacy\n",
        "\n",
        "for ent in doc.ents:\n",
        "\tprint(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
        "\n",
        "displacy.render(doc, style='ent',jupyter=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "APSVq6jse27D",
        "outputId": "cfca982f-893c-47d0-de76-95d6d31b42ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities [('Alto', 'PRODUCT')]\n",
            "Alto 16 20 PRODUCT\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I was driving a \n",
              "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Alto\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
              "</mark>\n",
              "</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing on audio transcription input"
      ],
      "metadata": {
        "id": "j_-AOA2ZgOlp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## SPEECH TO TEXT TRANSCRIPTION CODE HERE\n",
        "\n",
        "transcription = \"Do they have blond hair and purple glasses?\""
      ],
      "metadata": {
        "id": "fwQpytSv5UdX"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "doc = nlp(transcription)\n",
        "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])\n",
        "\n",
        "from spacy import displacy\n",
        "\n",
        "# for ent in doc.ents:\n",
        "# \tprint(ent.text, ent.start_char, ent.end_char, ent.label_)\n",
        "\n",
        "displacy.render(doc, style='ent',jupyter=True)\n",
        "\n",
        "## ent.text ('blond') and ent.label ('DATE', which will ultimately be 'hair_color') will then be sent to the game backend to check\n",
        "##\n",
        "## guess_trait = ent.label\n",
        "## guess_adj = ent.text\n",
        "## if guess_trait == guess_adj:\n",
        "##\t\treturn affirmative_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "DfNYmqxCgPvS",
        "outputId": "b00af295-6c74-46b4-c58f-887a25010542"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Entities [('blond', 'DATE')]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Do they have \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    blond\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " hair and purple glasses?</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "| Predefined Label  | Corresponds to our label \n",
        "| --- | --- |\n",
        "ORG | glasses\n",
        "DATE | hair_color\n",
        "NORP | hat_color\n",
        "GPE | hat\n",
        "LAW | bald"
      ],
      "metadata": {
        "id": "6KnuE35W7VKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the  model to directory\n",
        "output_dir = Path('/content/')\n",
        "nlp.to_disk(output_dir)\n",
        "print(\"Saved model to\", output_dir)\n",
        "\n",
        "# Load the saved model and predict\n",
        "print(\"Loading from\", output_dir)\n",
        "nlp_updated = spacy.load(output_dir)\n",
        "doc = nlp_updated(\"Fridge can be ordered in FlipKart\" )\n",
        "print(\"Entities\", [(ent.text, ent.label_) for ent in doc.ents])"
      ],
      "metadata": {
        "id": "AhtNSupMfHoM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}